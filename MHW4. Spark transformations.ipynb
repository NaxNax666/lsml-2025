{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b49ae99b",
   "metadata": {},
   "source": [
    "# Мини задание 4 (теперь бонусное)\n",
    "\n",
    "В рамках данной работы давайте еще поработаем со спарком и попытаемся обуздать его возможности для расширения вашего кругозора в используемых у него методах группировки данных и их различных агрегаций.\n",
    "\n",
    "Работать будем с известным нам датасетом airbnb из семинаров - https://www.kaggle.com/datasets/joebeachcapital/airbnb\n",
    "\n",
    "Для работы с данными в дз вам надо скачать архив этого датасета, вытащить из архива данные и разместить их на вашем hdfs хранилище.\n",
    "\n",
    "Материалы, которые вам точно понадобятся для этого дз есть в семинаре 5 - https://github.com/NaxNax666/lsml-2025/blob/main/05.%20Advansed%20Spark.ipynb\n",
    "\n",
    "И в рамках документации по работе с функциями трансофрмаций из спарка - https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html\n",
    "\n",
    "\n",
    "**Задание 1.** [1 балл] В разрезе каждого города (колонка `city`) выделите весь список удобств (`amenities`), предлагаемых в жилплощади из этих городов (учитывайте возможные дубли в этих данных). В ответе выведите фрейм данных со списком всех удобств для следующих городов: `Hoxton`, `Rainham`, `Rio Del Mar`. По ответам на эти города мы увидим, правильные ли преобразования для данных вы собрали.\n",
    "\n",
    "**Задание 2.** [1 балл] Также в разрезе каждого города выделите удобства, которые предлагаются в жилплощадях этих городов и выделите из них **топ-5 городов**, в жилье которых предлагается больше всего удобств. Учитывайте дубли в этих значениях относительно разного жилья, тут речь идет про поиск всех уникальных значений по городам и их подсчет для поиска самых `удобных` городов. В качестве ответа выведите фрейм данных с этими городами и числом уникальных удобств из них.\n",
    "\n",
    "**Задание 3.** [1 балл] Давайте выясним, по каким объявлениям можно пройти верификацию на оффер по жилью через `linkedin` (колонка `host_verifications`), что в реалиях airbnb достаточно забавно. Нам также подойдут варианты объявлений, где верификация через линкед будет одним из возможных вариантов. В ответе укажите кол-во объявлений из стран (колонка `country`) `Switzerland` и `Austria`, по которым можно пройти верификацию через линкед.\n",
    "\n",
    "**Задание 4.** [1 балл] Посмотрим объявления с большим кол-вом спален (колонка `bedrooms`). Найдите в наших данных объявления с 10 спальнями за самую высокую и самую низкую стоимости (колонка `price`). В ответ выведите фрейм данных с колонкой `id` по этим объявлениям. Учитывайте правильный тип данных для этого задания, чтобы получить верный ответ.\n",
    "\n",
    "**Задание 5.** [1 балл] Посмотрим на типы предлагаемого жилья (`property_type`) и их цену. Найдите в наших данных минимальную и максимальную стоимость для таких типов жилья как: `Car`, `Castle`, `Lighthouse`. В качестве ответа выведите фрей данных с этой инфой.\n",
    "\n",
    "\n",
    "**Важно!** В качестве результата у вас на каждое из заданий должен быть выведен спарк фрейм с ответом в ноутбук с вашими решениями. В рамках этого дз ничего скидывать в качестве ответов на облачное хранилище не нужно.\n",
    "\n",
    "Итого, в ноутбуке должны присутствовать:\n",
    "* Процесс скачки и укладывания датасета на hdfs\n",
    "* Ячейки с кодом на Spark для решения заданий\n",
    "\n",
    "Ограничение по функционалу - использование в спарке DataFrame API или же SQL API, крутить что-то питон скриптами или через пандас (данные все же небольшие) - **запрещено**. Задача дз разобраться именно в методах агрегации данных через спарк и в их возможностях для получения нужных вам результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2123e12c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
