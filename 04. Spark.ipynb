{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Spark\n",
    "\n",
    "Автор ноутбука: Алексей Космачев\n",
    "\n",
    "Сегодня будет говорить про Apache Spark - более удобный фреймворк для обработки больших данных на базе Hadoop.\n",
    "\n",
    "С Spark можно работать из ноутбуков в Data Sphere, но так как нам еще потребуется запускать bash команды, то я буду запускать все команды ниже из ноутбука на мастер-ноде\n",
    "\n",
    "PySpark - это не обычная библиотека, поэтому по-умолчанию ее нет в списке установленных пакетов\n",
    "\n",
    "Чтобы решить эту проблему простым способом, добрые люди сделали небольшую библиотеку findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 34.89501953125,
      "end_time": 1612352915112.742
     }
    }
   },
   "outputs": [],
   "source": [
    "! pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 68.73486328125,
      "end_time": 1612353023530.31
     }
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"lsml-app\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работаем с RDD\n",
    "\n",
    "RDD - это базовый строительный блок для Spark. Спарк внимательно следит за тем, где лежат части RDD и как они были созданы. RDD по сути своей представляют упорядоченный набор записей. Большое число функций считают, что это пары ключ-значение (также как было в MapReduce), но на деле это может быть и произвольные данные.\n",
    "\n",
    "RDD сами по себе неизменяемые. Можно лишь получить новый RDD, применяя различные операции к изначальному RDD.\n",
    "\n",
    "Существуют два вида операций над RDD - Действия (actions) и Трансформации (transformations).\n",
    "\n",
    "Трансформации не применяются сразу - они лишь записываются в пул примененных операций. Чтобы что-то действительно началось считаться, нужно применить уже действие - тогда все указанные транформации действительно начнут считаться на кластере.\n",
    "\n",
    "Давайте сразу смотреть на примерах, чтобы стало понятно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 347.635009765625,
      "end_time": 1612353266398.446
     }
    }
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(range(10))  # Создаем rdd из обычного списка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 95.464111328125,
      "end_time": 1612353269918.691
     }
    }
   },
   "outputs": [],
   "source": [
    "type(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 2343.68505859375,
      "end_time": 1612353297228.935
     }
    }
   },
   "outputs": [],
   "source": [
    "rdd.collect()  # Получить значение всего RDD в память. Аккуратнее - если RDD большой, у вас просто лопнем питон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 335.6630859375,
      "end_time": 1612353373733.558
     }
    }
   },
   "outputs": [],
   "source": [
    "rdd.count()  # Считаем количество элементов в RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 356.94091796875,
      "end_time": 1612353382653.109
     }
    }
   },
   "outputs": [],
   "source": [
    "rdd.first()  # Берем только первый элемент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 894.1611328125,
      "end_time": 1612353434994.542
     }
    }
   },
   "outputs": [],
   "source": [
    "rdd.take(2)  # Берем первые N элементов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 317.31005859375,
      "end_time": 1612353450417.845
     }
    }
   },
   "outputs": [],
   "source": [
    "rdd.mean()  # Считаем среднее по всем элементам. Важно, чтобы элементы внутри RDD поддерживали суммирование и деление\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 81.319091796875,
      "end_time": 1612353469108.061
     }
    }
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([\"biba\", \"kuka\"])  # Можем положить и строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 268.843017578125,
      "end_time": 1612353470625.169
     }
    }
   },
   "outputs": [],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -ls /user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -mkdir -p /user/spark-example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 6073.139892578125,
      "end_time": 1612353482524.937
     }
    }
   },
   "outputs": [],
   "source": [
    "! hdfs dfs -rm -r /user/spark-example/biba_and_kuka.txt || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 2377.29296875,
      "end_time": 1612353510464.038
     }
    }
   },
   "outputs": [],
   "source": [
    "rdd.saveAsTextFile(\"/user/spark-example/biba_and_kuka.txt\")  # Сохраняем RDD в HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 6995.572998046875,
      "end_time": 1612342093294.737
     }
    }
   },
   "outputs": [],
   "source": [
    "! hdfs dfs -ls /user/spark-example/biba_and_kuka.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 10939.029052734375,
      "end_time": 1612353580378.112
     }
    }
   },
   "outputs": [],
   "source": [
    "! hdfs dfs -cat /user/spark-example/biba_and_kuka.txt/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим теперь еще трансформации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 62.633056640625,
      "end_time": 1612353596244.709
     }
    }
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(range(10))  # Создаем rdd из обычного списка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 57.074951171875,
      "end_time": 1612353744051.49
     }
    }
   },
   "outputs": [],
   "source": [
    "# Создаем rdd в котором каждый элемент возведен в квадрат\n",
    "# map работает примерно также как и map в MapReduce. \n",
    "# Разница - мы не обрабатываем блок самостоятельно, а пишем функцию для обработки ровно одной записи\n",
    "squares = rdd.map(lambda x: x**2).map(lambda x: x + 1)\n",
    "\n",
    "# ВАЖНО - на самом деле ничего считаться в этот момент не начало\n",
    "# Мы лишь записали наше желание получить новый RDD и записали это желание в squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 321.33203125,
      "end_time": 1612353744490.673
     }
    }
   },
   "outputs": [],
   "source": [
    "squares.first() \n",
    "\n",
    "# Так как мы применили Action то вот теперь все трансформации запустились\n",
    "# Но так как action требует только первую строку, то Spark оптимизировал вычисления\n",
    "# он прочитал только первую строку и для нее вычислил значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 354.3359375,
      "end_time": 1612353744887.548
     }
    }
   },
   "outputs": [],
   "source": [
    "squares.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Начнем работать с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет - тот же, что и на предыдущем семинаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -ls -h /user/tweets/data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 296.0029296875,
      "end_time": 1612353840629.932
     }
    }
   },
   "outputs": [],
   "source": [
    "data = sc.textFile(\"/user/tweets/data/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 873.843994140625,
      "end_time": 1612353845982.603
     }
    }
   },
   "outputs": [],
   "source": [
    "data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 136.76708984375,
      "end_time": 1612353905752.842
     }
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def extract_text(raw_string):\n",
    "    parsed_line = next(csv.reader([raw_string]))\n",
    "    text = parsed_line[2]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 830.344970703125,
      "end_time": 1612353924927.376
     }
    }
   },
   "outputs": [],
   "source": [
    "data.map(extract_text).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 91.820068359375,
      "end_time": 1612354017669.193
     }
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_words(text):\n",
    "    pattern = re.compile(r\"[a-z]+\")\n",
    "    result = []\n",
    "    for match in pattern.finditer(text.lower()):\n",
    "        word = match.group(0)\n",
    "        result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 816.132080078125,
      "end_time": 1612354050310.284
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.map(extract_text).map(extract_words).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 823.447021484375,
      "end_time": 1612354082447.02
     }
    }
   },
   "outputs": [],
   "source": [
    "data.map(extract_text).flatMap(extract_words).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 814.89306640625,
      "end_time": 1612354091193.413
     }
    }
   },
   "outputs": [],
   "source": [
    "data.map(extract_text).flatMap(extract_words).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все трансформации вычисляются каждый раз с самого первого RDD. Чтобы уменьшить количество лишних вычислений можно закешировать временный результат. Тогда он будет по максимуму переиспользоваться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 295.781982421875,
      "end_time": 1612354213990.163
     }
    }
   },
   "outputs": [],
   "source": [
    "words = data.map(extract_text).flatMap(extract_words).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 19594.058837890625,
      "end_time": 1612354236725.854
     }
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "words.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 2308.721923828125,
      "end_time": 1612354257919.374
     }
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "words.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На моем запуске второй запуск `words.count()` работал 2 секунды вместо 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word count\n",
    "\n",
    "Попробуем реализовать тот же алгоритм, что и для классического MapReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 259.268798828125,
      "end_time": 1612354326981.429
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('we', 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.map(lambda x: (x, 1)).first()  # Строим пары ключ значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 23503.94384765625,
      "end_time": 1612354363998.507
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ioam', <pyspark.resultiterable.ResultIterable at 0x7f3ad525c1c0>),\n",
       " ('mgkdv', <pyspark.resultiterable.ResultIterable at 0x7f3ad525c4f0>)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    words\n",
    "    .map(lambda x: (x, 1))\n",
    "    .groupByKey()  # Функция работает, только если RDD - это пары ключ-значение\n",
    "    .take(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 23478.2060546875,
      "end_time": 1612354432752.624
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kaoj', 2),\n",
       " ('vwc', 35),\n",
       " ('jz', 1428),\n",
       " ('oydamf', 1),\n",
       " ('kbaraft', 1),\n",
       " ('russian', 9339),\n",
       " ('j', 57058),\n",
       " ('cjv', 39),\n",
       " ('suvqmtnfc', 1),\n",
       " ('snzhetpngt', 1)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ПЛОХОЙ ВАРИАНТ: материализуем весь x через list\n",
    "(\n",
    "    words\n",
    "    .map(lambda x: (x, 1))\n",
    "    .groupByKey()  # Функция работает, только если RDD - это пары ключ-значение\n",
    "    .map(lambda x: (x[0], sum(list(x[1]))))\n",
    "    .take(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ioam', 1),\n",
       " ('mgkdv', 1),\n",
       " ('nvp', 45),\n",
       " ('ga', 2607),\n",
       " ('ymivb', 1),\n",
       " ('moddv', 1),\n",
       " ('sifli', 1),\n",
       " ('j', 57058),\n",
       " ('xsgvay', 1),\n",
       " ('qxa', 56)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ИСПРАВЛЕННЫЙ ВАРИАНТ\n",
    "(\n",
    "    words\n",
    "    .map(lambda x: (x, 1))\n",
    "    .groupByKey()  # Функция работает, только если RDD - это пары ключ-значение\n",
    "    .map(lambda x: (x[0], sum(x[1])))\n",
    "    .take(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 17406.94287109375,
      "end_time": 1612354558105.175
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('karts', 26),\n",
       " ('this', 118604),\n",
       " ('decades', 1338),\n",
       " ('concert', 1561),\n",
       " ('alerts', 162),\n",
       " ('lil', 2852),\n",
       " ('uzi', 298),\n",
       " ('overpaid', 38),\n",
       " ('journalist', 1364),\n",
       " ('million', 12651)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    words\n",
    "    .map(lambda x: (x, 1))\n",
    "    .reduceByKey(lambda a, b: a + b)  # Если уже готовая функция для reduce\n",
    "    .take(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ioam', 1),\n",
       " ('mgkdv', 1),\n",
       " ('nvp', 45),\n",
       " ('ga', 2607),\n",
       " ('ymivb', 1),\n",
       " ('moddv', 1),\n",
       " ('sifli', 1),\n",
       " ('j', 57058),\n",
       " ('xsgvay', 1),\n",
       " ('qxa', 56)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import add\n",
    "\n",
    "# то же самое с помощью оператора самого спарка\n",
    "\n",
    "(\n",
    "    words\n",
    "    .map(lambda x: (x, 1))\n",
    "    .reduceByKey(add) \n",
    "    .take(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 17426.239013671875,
      "end_time": 1612354616853.129
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('t', 3015051),\n",
       " ('co', 2833375),\n",
       " ('https', 2454132),\n",
       " ('the', 591885),\n",
       " ('to', 589004),\n",
       " ('in', 457433),\n",
       " ('a', 412888),\n",
       " ('s', 397889),\n",
       " ('http', 375299),\n",
       " ('of', 350983)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    words\n",
    "    .map(lambda x: (x, 1))\n",
    "    .reduceByKey(lambda a, b: a + b)\n",
    "    .takeOrdered(10, lambda x: -x[1])  # Сортируем по значению функции\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 17466.43701171875,
      "end_time": 1612354698072.037
     }
    }
   },
   "outputs": [],
   "source": [
    "result_50 = (\n",
    "    words\n",
    "    .map(lambda x: (x, 1))\n",
    "    .reduceByKey(lambda a, b: a + b)\n",
    "    .takeOrdered(50, lambda x: -x[1])\n",
    ")\n",
    "\n",
    "stop_words = [word for word, _ in result_50]  # Предподсчитали стоп слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 66.18798828125,
      "end_time": 1612354698177.797
     }
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('t', 3015051),\n",
       " ('co', 2833375),\n",
       " ('https', 2454132),\n",
       " ('the', 591885),\n",
       " ('to', 589004),\n",
       " ('in', 457433),\n",
       " ('a', 412888),\n",
       " ('s', 397889),\n",
       " ('http', 375299),\n",
       " ('of', 350983),\n",
       " ('i', 287232),\n",
       " ('for', 272995),\n",
       " ('and', 247749),\n",
       " ('is', 246856),\n",
       " ('on', 210172),\n",
       " ('you', 196950),\n",
       " ('trump', 169520),\n",
       " ('news', 156101),\n",
       " ('it', 152816),\n",
       " ('with', 134178),\n",
       " ('at', 122223),\n",
       " ('that', 121017),\n",
       " ('this', 118604),\n",
       " ('rt', 105235),\n",
       " ('m', 100630),\n",
       " ('are', 96134),\n",
       " ('be', 95034),\n",
       " ('u', 93964),\n",
       " ('my', 86895),\n",
       " ('not', 84031),\n",
       " ('we', 83842),\n",
       " ('by', 82008),\n",
       " ('from', 78438),\n",
       " ('d', 72076),\n",
       " ('your', 71987),\n",
       " ('as', 71947),\n",
       " ('new', 71620),\n",
       " ('r', 70124),\n",
       " ('have', 67863),\n",
       " ('all', 67414),\n",
       " ('n', 67290),\n",
       " ('k', 66649),\n",
       " ('he', 66116),\n",
       " ('will', 65797),\n",
       " ('f', 65528),\n",
       " ('w', 65202),\n",
       " ('was', 64973),\n",
       " ('after', 64928),\n",
       " ('who', 64448),\n",
       " ('they', 64167)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 23490.77099609375,
      "end_time": 1612354745158.972
     }
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('just', 63572),\n",
       " ('what', 62512),\n",
       " ('c', 62430),\n",
       " ('e', 62022),\n",
       " ('b', 61064),\n",
       " ('about', 60260),\n",
       " ('police', 59042),\n",
       " ('up', 58757),\n",
       " ('l', 58478),\n",
       " ('can', 58178),\n",
       " ('g', 57828),\n",
       " ('o', 57769),\n",
       " ('p', 57638),\n",
       " ('man', 57610),\n",
       " ('j', 57058),\n",
       " ('x', 56777),\n",
       " ('h', 56523),\n",
       " ('y', 56216),\n",
       " ('no', 55914),\n",
       " ('out', 55858),\n",
       " ('v', 55327),\n",
       " ('people', 55169),\n",
       " ('me', 54160),\n",
       " ('but', 53036),\n",
       " ('sports', 52223),\n",
       " ('so', 52082),\n",
       " ('if', 51593),\n",
       " ('obama', 50655),\n",
       " ('z', 50303),\n",
       " ('q', 50137),\n",
       " ('his', 49153),\n",
       " ('us', 47572),\n",
       " ('world', 47475),\n",
       " ('how', 46947),\n",
       " ('get', 46941),\n",
       " ('like', 46806),\n",
       " ('more', 46580),\n",
       " ('has', 45670),\n",
       " ('do', 45175),\n",
       " ('an', 44963),\n",
       " ('now', 44180),\n",
       " ('politics', 44031),\n",
       " ('don', 43979),\n",
       " ('when', 43894),\n",
       " ('amp', 43392),\n",
       " ('one', 43370),\n",
       " ('our', 43246),\n",
       " ('over', 42735),\n",
       " ('workout', 42437),\n",
       " ('black', 40133)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    words\n",
    "    .filter(lambda x: x not in stop_words)\n",
    "    .map(lambda x: (x, 1))\n",
    "    .reduceByKey(lambda a, b: a + b)\n",
    "    .takeOrdered(50, lambda x: -x[1])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме базовых, есть еще и много продвинутых сложных функций\n",
    "Например можем посчитать уникальные слова в датасете\n",
    "\n",
    "Список всех можно смотреть в документации\n",
    "\n",
    "https://spark.apache.org/docs/latest/rdd-programming-guide.html#actions\n",
    "\n",
    "https://spark.apache.org/docs/latest/rdd-programming-guide.html#transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 15403.302001953125,
      "end_time": 1612354828533.726
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ioam', 'mgkdv', 'nvp', 'ga', 'ymivb', 'moddv', 'sifli', 'j', 'xsgvay', 'qxa']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.distinct().take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 17425.8349609375,
      "end_time": 1612354845992.719
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2831736"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако иногда каких-то базовых примитивов может и не найтись. Например для RDD нет функции `limit` или около того.\n",
    "\n",
    "Поэтому чтобы решить задачу top10 и сохранить это в HDFS нужно применить некоторую изобретательность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 29512.59814453125,
      "end_time": 1612354979955.66
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((63572, 'just'), 0),\n",
       " ((62512, 'what'), 1),\n",
       " ((62430, 'c'), 2),\n",
       " ((62022, 'e'), 3),\n",
       " ((61064, 'b'), 4),\n",
       " ((60260, 'about'), 5),\n",
       " ((59042, 'police'), 6),\n",
       " ((58757, 'up'), 7),\n",
       " ((58478, 'l'), 8),\n",
       " ((58178, 'can'), 9)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    words\n",
    "    .filter(lambda x: x not in stop_words)\n",
    "    .map(lambda x: (x, 1))\n",
    "    .reduceByKey(lambda a, b: a + b)\n",
    "    .map(lambda x: (x[1], x[0]))\n",
    "    .sortByKey(ascending=False)\n",
    "    .zipWithIndex()\n",
    "    .take(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 31554.372802734375,
      "end_time": 1612355051481.705
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(63572, 'just'),\n",
       " (62512, 'what'),\n",
       " (62430, 'c'),\n",
       " (62022, 'e'),\n",
       " (61064, 'b'),\n",
       " (60260, 'about'),\n",
       " (59042, 'police'),\n",
       " (58757, 'up'),\n",
       " (58478, 'l'),\n",
       " (58178, 'can')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    words\n",
    "    .filter(lambda x: x not in stop_words)\n",
    "    .map(lambda x: (x, 1))\n",
    "    .reduceByKey(lambda a, b: a + b)\n",
    "    .map(lambda x: (x[1], x[0]))\n",
    "    .sortByKey(ascending=False)\n",
    "    .zipWithIndex()\n",
    "    .filter(lambda x: x[1] < 10)\n",
    "    .map(lambda x: x[0])\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 items\r\n",
      "drwxr-xr-x   - ubuntu hadoop          0 2025-02-03 15:02 /user/tweets/data\r\n",
      "drwxr-xr-x   - ubuntu hadoop          0 2025-02-03 15:16 /user/tweets/lang-dist\r\n",
      "drwxr-xr-x   - ubuntu hadoop          0 2025-02-03 15:16 /user/tweets/mistake\r\n",
      "drwxr-xr-x   - ubuntu hadoop          0 2025-02-03 15:08 /user/tweets/result\r\n",
      "drwxr-xr-x   - ubuntu hadoop          0 2025-02-03 15:11 /user/tweets/result-fast1\r\n",
      "drwxr-xr-x   - ubuntu hadoop          0 2025-02-03 15:13 /user/tweets/result-fast2\r\n",
      "drwxr-xr-x   - ubuntu hadoop          0 2025-02-03 15:44 /user/tweets/spark\r\n",
      "drwxr-xr-x   - ubuntu hadoop          0 2025-02-03 15:09 /user/tweets/top10\r\n",
      "drwxr-xr-x   - ubuntu hadoop          0 2025-02-03 15:13 /user/tweets/top10-fast\r\n",
      "drwxr-xr-x   - ubuntu hadoop          0 2025-02-03 15:10 /user/tweets/top10-stop-words\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /user/tweets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 7770.451171875,
      "end_time": 1612355087945.224
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /user/tweets/spark/top10\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -rm -r /user/tweets/spark/top10 || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 33516.773193359375,
      "end_time": 1612355130340.745
     }
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    words\n",
    "    .filter(lambda x: x not in stop_words)\n",
    "    .map(lambda x: (x, 1))\n",
    "    .reduceByKey(lambda a, b: a + b)\n",
    "    .map(lambda x: (x[1], x[0]))\n",
    "    .sortByKey(ascending=False)\n",
    "    .zipWithIndex()\n",
    "    .filter(lambda x: x[1] < 10)\n",
    "    .map(lambda x: x[0])\n",
    "    .saveAsTextFile('/user/tweets/spark/top10')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 items\r\n",
      "-rw-r--r--   1 ubuntu hadoop          0 2025-02-03 17:31 /user/tweets/spark/top10/_SUCCESS\r\n",
      "-rw-r--r--   1 ubuntu hadoop        148 2025-02-03 17:31 /user/tweets/spark/top10/part-00000\r\n",
      "-rw-r--r--   1 ubuntu hadoop          0 2025-02-03 17:31 /user/tweets/spark/top10/part-00001\r\n",
      "-rw-r--r--   1 ubuntu hadoop          0 2025-02-03 17:31 /user/tweets/spark/top10/part-00002\r\n",
      "-rw-r--r--   1 ubuntu hadoop          0 2025-02-03 17:31 /user/tweets/spark/top10/part-00003\r\n",
      "-rw-r--r--   1 ubuntu hadoop          0 2025-02-03 17:31 /user/tweets/spark/top10/part-00004\r\n",
      "-rw-r--r--   1 ubuntu hadoop          0 2025-02-03 17:31 /user/tweets/spark/top10/part-00005\r\n",
      "-rw-r--r--   1 ubuntu hadoop          0 2025-02-03 17:31 /user/tweets/spark/top10/part-00006\r\n",
      "-rw-r--r--   1 ubuntu hadoop          0 2025-02-03 17:31 /user/tweets/spark/top10/part-00007\r\n",
      "-rw-r--r--   1 ubuntu hadoop          0 2025-02-03 17:31 /user/tweets/spark/top10/part-00008\r\n",
      "-rw-r--r--   1 ubuntu hadoop          0 2025-02-03 17:31 /user/tweets/spark/top10/part-00009\r\n",
      "-rw-r--r--   1 ubuntu hadoop          0 2025-02-03 17:31 /user/tweets/spark/top10/part-00010\r\n",
      "-rw-r--r--   1 ubuntu hadoop          0 2025-02-03 17:31 /user/tweets/spark/top10/part-00011\r\n",
      "-rw-r--r--   1 ubuntu hadoop          0 2025-02-03 17:31 /user/tweets/spark/top10/part-00012\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls -h /user/tweets/spark/top10/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(63572, 'just'),\n",
       "  (62512, 'what'),\n",
       "  (62430, 'c'),\n",
       "  (62022, 'e'),\n",
       "  (61064, 'b'),\n",
       "  (60260, 'about'),\n",
       "  (59042, 'police'),\n",
       "  (58757, 'up'),\n",
       "  (58478, 'l'),\n",
       "  (58178, 'can')],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    words\n",
    "    .filter(lambda x: x not in stop_words)\n",
    "    .map(lambda x: (x, 1))\n",
    "    .reduceByKey(lambda a, b: a + b)\n",
    "    .map(lambda x: (x[1], x[0]))\n",
    "    .sortByKey(ascending=False)\n",
    "    .zipWithIndex()\n",
    "    .filter(lambda x: x[1] < 10)\n",
    "    .map(lambda x: x[0])\n",
    "    .glom().collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 8163.9921875,
      "end_time": 1612355138511.746
     }
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63572, 'just')\r\n",
      "(62512, 'what')\r\n",
      "(62430, 'c')\r\n",
      "(62022, 'e')\r\n",
      "(61064, 'b')\r\n",
      "(60260, 'about')\r\n",
      "(59042, 'police')\r\n",
      "(58757, 'up')\r\n",
      "(58478, 'l')\r\n",
      "(58178, 'can')\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -cat /user/tweets/spark/top10/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partitions\n",
    "\n",
    "Под капотом Spark эксплуатирует примерно те же идеи, что и классический MapReduce. Это означает, что при необходимости сортировки, он разбивает ключи на группы и передает редюсерам на обработку только их часть.\n",
    "\n",
    "На этот процесс также можно влиять. Это может позводить улучшить производительность программ, а также решить проблемы переполнения редюсеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 51.573974609375,
      "end_time": 1612355288369.505
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 48.348876953125,
      "end_time": 1612355336156.765
     }
    }
   },
   "outputs": [],
   "source": [
    "numbers = sc.parallelize(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 304.620849609375,
      "end_time": 1612355357451.627
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1, 2], [3, 4], [5], [6, 7], [8, 9]]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers.glom().collect()  # Получаем доступ до данных в каждей партиции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 144.0498046875,
      "end_time": 1612355446560.521
     }
    }
   },
   "outputs": [],
   "source": [
    "squares = numbers.map(lambda x: (x, x**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 111.16015625,
      "end_time": 1612346527646.15
     }
    }
   },
   "source": [
    "Операции изменения партиций предполагают наличие ключа, поэтому вначале преобразуем данные к виду ключ-значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 301.077880859375,
      "end_time": 1612355479629.363
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2, 4), (6, 36), (0, 0), (4, 16), (8, 64)],\n",
       " [(5, 25), (1, 1), (7, 49), (3, 9), (9, 81)]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squares.partitionBy(2).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 800.200927734375,
      "end_time": 1612355511548.453
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0)],\n",
       " [(1, 1)],\n",
       " [(2, 4)],\n",
       " [(3, 9)],\n",
       " [(4, 16)],\n",
       " [(5, 25)],\n",
       " [(6, 36)],\n",
       " [(7, 49)],\n",
       " [(8, 64)],\n",
       " [(9, 81)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squares.partitionBy(15).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 91.37109375,
      "end_time": 1612355551455.15
     }
    }
   },
   "outputs": [],
   "source": [
    "def custom_partitioner(key):\n",
    "    return key % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 806.29296875,
      "end_time": 1612355558129.937
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(6, 36), (3, 9), (9, 81), (0, 0)],\n",
       " [(4, 16), (1, 1), (7, 49)],\n",
       " [(5, 25), (8, 64), (2, 4)]]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squares.partitionBy(3, custom_partitioner).glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом можно выбирать более удачные способы разбиения и например увеличивать количество редюсеров под вашу задачу.\n",
    "\n",
    "Или наоборот, уменьшать количество количество партиций, если они избыточны. Например вы отфильтровали гигантский датасет и теперь вам больше не требуется такое гигантское количество партиций для работы.\n",
    "\n",
    "Для этого можно использовать и `repartition` как делали выше, однако этот метод запустит пересортировку вообще всего RDD, что дорого и излишне. Чтобы так не было, можно использовать функцию `coalesce` - она просто схлопнуть вместе те партиции, котороые уже находятся на одной машине, что значительно уменьшит количество лишних телодвижений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 335.170166015625,
      "end_time": 1612355585653.388
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = sc.parallelize(range(10), 10) # явно указали вторым аргументом количество партиций\n",
    "numbers.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "squares = numbers.map(lambda x: (x, x**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 267.27197265625,
      "end_time": 1612355612327.429
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], [], [], [], [], [], [(7, 49)], [(8, 64)], [(9, 81)]]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squares.filter(lambda x: x[0] >= 7).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 816.72802734375,
      "end_time": 1612355755256.698
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [(7, 49), (8, 64), (9, 81)]]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squares.filter(lambda x: x[0] >= 7).coalesce(2).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(6, 36), (8, 64)], [(5, 25), (7, 49), (9, 81)]]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squares.filter(lambda x: x[0] >= 5).repartition(2).glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame и SQL\n",
    "\n",
    "Уже текущий набор функций - это большой шаг вперед относительно классического MapReduce. Однако на этом плюшки Spark не заканчиваются. Разработчики пошли дальше и начали внедрять еще более высокоуровневый интерфейс для работы с данными, который может сильно упростить жизнь разработчикам.\n",
    "\n",
    "DataFrame - это модель таблицы, построенная поверх RDD. О ней можно думать как о Pandas на стероидах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 276.751953125,
      "end_time": 1612355862565.257
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('a', 2), ('b', 3), ('b', 4)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([(\"a\", 1), (\"a\", 2), (\"b\", 3), (\"b\", 4)])\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 184.1630859375,
      "end_time": 1612355868876.816
     }
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "se = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 3370.230224609375,
      "end_time": 1612355896303.066
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: string (nullable = true)\n",
      " |-- _2: long (nullable = true)\n",
      "\n",
      "+---+---+\n",
      "| _1| _2|\n",
      "+---+---+\n",
      "|  a|  1|\n",
      "|  a|  2|\n",
      "|  b|  3|\n",
      "|  b|  4|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = se.createDataFrame(rdd)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 790.541015625,
      "end_time": 1612355952915.348
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pipa: string (nullable = true)\n",
      " |-- pupa: long (nullable = true)\n",
      "\n",
      "+----+----+\n",
      "|pipa|pupa|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "|   a|   2|\n",
      "|   b|   3|\n",
      "|   b|   4|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = se.createDataFrame(\n",
    "    rdd.map(lambda x: Row(pipa=x[0], pupa=x[1]))\n",
    ")\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства есть встроенные функции конвертации в pandas и оттуда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 397.39306640625,
      "end_time": 1612355971061.935
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipa</th>\n",
       "      <th>pupa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pipa  pupa\n",
       "0    a     1\n",
       "1    a     2\n",
       "2    b     3\n",
       "3    b     4"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df = df.toPandas()\n",
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 769.448974609375,
      "end_time": 1612355984886.015
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pipa: string (nullable = true)\n",
      " |-- pupa: long (nullable = true)\n",
      "\n",
      "+----+----+\n",
      "|pipa|pupa|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "|   a|   2|\n",
      "|   b|   3|\n",
      "|   b|   4|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = se.createDataFrame(pandas_df)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть специальные функции, которые умеют работать с популярными форматами хранения таблиц, и строить их в HDFS.\n",
    "\n",
    "Прочтем нашу таблицу через DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 13481.74609375,
      "end_time": 1612356061360.093
     }
    }
   },
   "outputs": [],
   "source": [
    "df = se.read.csv('/user/tweets/data/*', header=False, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 69.850830078125,
      "end_time": 1612356061473.22
     }
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      " |-- _c20: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 81.527099609375,
      "end_time": 1612356081724.692
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- external_author_id: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- publish_date: string (nullable = true)\n",
      " |-- harvested_date: string (nullable = true)\n",
      " |-- following: string (nullable = true)\n",
      " |-- followers: string (nullable = true)\n",
      " |-- updates: string (nullable = true)\n",
      " |-- post_type: string (nullable = true)\n",
      " |-- account_type: string (nullable = true)\n",
      " |-- retweet: string (nullable = true)\n",
      " |-- account_category: string (nullable = true)\n",
      " |-- new_june_2018: string (nullable = true)\n",
      " |-- alt_external_id: string (nullable = true)\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- article_url: string (nullable = true)\n",
      " |-- tco1_step1: string (nullable = true)\n",
      " |-- tco2_step1: string (nullable = true)\n",
      " |-- tco3_step1: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = [\n",
    "    'external_author_id',\n",
    "    'author',\n",
    "    'content',\n",
    "    'region',\n",
    "    'language',\n",
    "    'publish_date',\n",
    "    'harvested_date',\n",
    "    'following',\n",
    "    'followers',\n",
    "    'updates',\n",
    "    'post_type',\n",
    "    'account_type',\n",
    "    'retweet',\n",
    "    'account_category',\n",
    "    'new_june_2018',\n",
    "    'alt_external_id',\n",
    "    'tweet_id',\n",
    "    'article_url',\n",
    "    'tco1_step1',\n",
    "    'tco2_step1',\n",
    "    'tco3_step1'\n",
    "]\n",
    "df = df.toDF(*columns)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 792.657958984375,
      "end_time": 1612356091152.882
     }
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+--------------------+--------------------+-------------+---------------+---------------+--------------+---------+-------+---------+------------+-------+----------------+-------------+---------------+------------------+--------------------+--------------------+--------------------+----------+\n",
      "|external_author_id|         author|             content|              region|     language|   publish_date| harvested_date|     following|followers|updates|post_type|account_type|retweet|account_category|new_june_2018|alt_external_id|          tweet_id|         article_url|          tco1_step1|          tco2_step1|tco3_step1|\n",
      "+------------------+---------------+--------------------+--------------------+-------------+---------------+---------------+--------------+---------+-------+---------+------------+-------+----------------+-------------+---------------+------------------+--------------------+--------------------+--------------------+----------+\n",
      "|        1647045721|CARRIETHORNTHON|New Study Reveals...|       United States|      English| 6/1/2015 22:04| 6/1/2015 22:04|            80|      207|   1193|  RETWEET|       Right|      1|      RightTroll|            0|     1647045721|605495107186364419|http://twitter.co...|http://gopthedail...|                null|      null|\n",
      "|        1647045721|CARRIETHORNTHON|Lindsey Graham ha...|       United States|      English| 6/1/2015 22:04| 6/1/2015 22:04|            80|      207|   1195|  RETWEET|       Right|      1|      RightTroll|            0|     1647045721|605495132540911616|http://twitter.co...|https://twitter.c...|http://huff.to/1K...|      null|\n",
      "|        1647045721|CARRIETHORNTHON|. @LindseyGrahamS...|       United States|      English| 6/1/2015 22:04| 6/1/2015 22:04|            80|      207|   1202|  RETWEET|       Right|      1|      RightTroll|            0|     1647045721|605495257694740480|http://twitter.co...|https://twitter.c...|http://goo.gl/p9jwId|      null|\n",
      "|        1647045721|CARRIETHORNTHON|2016 Power Index:...|       United States|      English| 6/1/2015 22:04| 6/1/2015 22:04|            80|      207|   1200|  RETWEET|       Right|      1|      RightTroll|            0|     1647045721|605495223045619712|http://twitter.co...|https://twitter.c...|http://fxn.ws/1Ky...|      null|\n",
      "|        1647045721|CARRIETHORNTHON|I self identify a...|       United States|      English| 6/1/2015 22:05| 6/1/2015 22:05|            80|      207|   1207|  RETWEET|       Right|      1|      RightTroll|            0|     1647045721|605495365916196864|http://twitter.co...|                null|                null|      null|\n",
      "|        1647045721|CARRIETHORNTHON|.@UW varsity eigh...|       United States|      English| 6/1/2015 22:05| 6/1/2015 22:05|            80|      207|   1204|  RETWEET|       Right|      1|      RightTroll|            0|     1647045721|605495299197370368|http://twitter.co...|https://twitter.c...|http://seati.ms/1...|      null|\n",
      "|        1647045721|CARRIETHORNTHON|Since the 1980s a...|       United States|      English| 6/1/2015 22:05| 6/1/2015 22:05|            80|      207|   1205|  RETWEET|       Right|      1|      RightTroll|            0|     1647045721|605495319070048257|http://twitter.co...|http://econ.st/1H...|                null|      null|\n",
      "|        1647045721|CARRIETHORNTHON|Records: Wife Sus...|       United States|      English| 6/1/2015 22:05| 6/1/2015 22:05|            80|      207|   1206|  RETWEET|       Right|      1|      RightTroll|            0|     1647045721|605495344613294080|http://twitter.co...|http://goo.gl/DlcFs4|                null|      null|\n",
      "|        1647045721|CARRIETHORNTHON|\"\"\"It will create...|       United States|      English| 6/1/2015 22:05| 6/1/2015 22:05|            80|      207|   1208|  RETWEET|       Right|      1|      RightTroll|            0|     1647045721|605495384262066178|http://twitter.co...|https://twitter.c...|http://bbc.in/1dH...|      null|\n",
      "|        1647045721|CARRIETHORNTHON|The good news abo...|       United States|      English| 6/1/2015 22:05| 6/1/2015 22:07|            80|      207|   1211|  RETWEET|       Right|      1|      RightTroll|            0|     1647045721|605495447457636356|http://twitter.co...|http://goo.gl/Pb9TH5|                null|      null|\n",
      "|        1647045721|CARRIETHORNTHON|\"\"\"Culture fit\"\" ...| but it doesn't h...|United States|        English| 6/1/2015 22:05|6/1/2015 22:05|       80|    207|     1210|     RETWEET|  Right|               1|   RightTroll|              0|        1647045721|  605495428843372544|http://twitter.co...|http://www.nytime...|      null|\n",
      "|        1647045721|CARRIETHORNTHON|Things to Know Ab...|       United States|      English| 6/1/2015 22:05| 6/1/2015 22:05|            80|      207|   1209|  RETWEET|       Right|      1|      RightTroll|            0|     1647045721|605495408370909184|http://twitter.co...|http://goo.gl/oxpVq9|                null|      null|\n",
      "|        1647045721|CARRIETHORNTHON|This is what happ...|       United States|      English|6/13/2015 22:18|6/13/2015 22:18|            80|      209|   1227|  RETWEET|       Right|      1|      RightTroll|            0|     1647045721|609847416435535872|http://twitter.co...|https://twitter.c...|http://i100.io/0Y...|      null|\n",
      "|        1647045721|CARRIETHORNTHON|#FloridaMan throw...|       United States|      English|6/13/2015 22:18|6/13/2015 22:19|            80|      209|   1229|  RETWEET|       Right|      1|      RightTroll|            0|     1647045721|609847457036414976|http://twitter.co...|https://twitter.c...|http://bit.ly/1FH...|      null|\n",
      "|        1647045721|CARRIETHORNTHON|Report: DHS 'Red-...|       United States|      English|6/13/2015 22:18|6/13/2015 22:18|            80|      209|   1228|  RETWEET|       Right|      1|      RightTroll|            0|     1647045721|609847441005752320|http://twitter.co...|http://bit.ly/1FH...|                null|      null|\n",
      "|        1647045721|CARRIETHORNTHON|More proof that T...|       United States|      English|6/13/2015 22:19|6/13/2015 22:19|            81|      209|   1233|  RETWEET|       Right|      1|      RightTroll|            0|     1647045721|609847511574917120|http://twitter.co...|https://twitter.c...|http://i100.io/Kf...|      null|\n",
      "|        1647045721|CARRIETHORNTHON|World Naked Bike ...|       United States|      English|6/13/2015 22:19|6/13/2015 22:19|            81|      209|   1235|  RETWEET|       Right|      1|      RightTroll|            0|     1647045721|609847556835639296|http://twitter.co...|http://on.mash.to...|                null|      null|\n",
      "|        1647045721|CARRIETHORNTHON|#Business — New @...|       United States|      English|6/13/2015 22:19|6/13/2015 22:19|            81|      209|   1230|  RETWEET|       Right|      1|      RightTroll|            0|     1647045721|609847471309631488|http://twitter.co...|http://bit.ly/1JQ...|                null|      null|\n",
      "|        1647045721|CARRIETHORNTHON|Pre-Game warm up ...|       United States|      English|6/13/2015 22:19|6/13/2015 22:19|            81|      209|   1237|  RETWEET|       Right|      1|      RightTroll|            0|     1647045721|609847582915850240|http://twitter.co...|http://bit.ly/1JQ...|                null|      null|\n",
      "|        1647045721|CARRIETHORNTHON|#News — Retired #...|       United States|      English|6/13/2015 22:19|6/13/2015 22:19|            81|      209|   1234|  RETWEET|       Right|      1|      RightTroll|            0|     1647045721|609847534169632768|http://twitter.co...|https://twitter.c...|http://bit.ly/1FP...|      null|\n",
      "+------------------+---------------+--------------------+--------------------+-------------+---------------+---------------+--------------+---------+-------+---------+------------+-------+----------------+-------------+---------------+------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 810.4111328125,
      "end_time": 1612356117686.434
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "|         author|             content|\n",
      "+---------------+--------------------+\n",
      "|CARRIETHORNTHON|New Study Reveals...|\n",
      "|CARRIETHORNTHON|Lindsey Graham ha...|\n",
      "|CARRIETHORNTHON|. @LindseyGrahamS...|\n",
      "|CARRIETHORNTHON|2016 Power Index:...|\n",
      "|CARRIETHORNTHON|I self identify a...|\n",
      "|CARRIETHORNTHON|.@UW varsity eigh...|\n",
      "|CARRIETHORNTHON|Since the 1980s a...|\n",
      "|CARRIETHORNTHON|Records: Wife Sus...|\n",
      "|CARRIETHORNTHON|\"\"\"It will create...|\n",
      "|CARRIETHORNTHON|The good news abo...|\n",
      "+---------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[['author', 'content']].show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 329.391845703125,
      "end_time": 1612356292166.772
     }
    }
   },
   "outputs": [],
   "source": [
    "df.registerTempTable('tweets')  # Регистрируем как временную таблицу для SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 3312.72412109375,
      "end_time": 1612356401518.544
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+---------+\n",
      "|         author|             content|followers|\n",
      "+---------------+--------------------+---------+\n",
      "|CARRIETHORNTHON|New Study Reveals...|      207|\n",
      "|CARRIETHORNTHON|Lindsey Graham ha...|      207|\n",
      "|CARRIETHORNTHON|. @LindseyGrahamS...|      207|\n",
      "|CARRIETHORNTHON|2016 Power Index:...|      207|\n",
      "|CARRIETHORNTHON|I self identify a...|      207|\n",
      "|CARRIETHORNTHON|.@UW varsity eigh...|      207|\n",
      "|CARRIETHORNTHON|Since the 1980s a...|      207|\n",
      "|CARRIETHORNTHON|Records: Wife Sus...|      207|\n",
      "|CARRIETHORNTHON|\"\"\"It will create...|      207|\n",
      "|CARRIETHORNTHON|The good news abo...|      207|\n",
      "+---------------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "se.sql(\"\"\"\n",
    "    SELECT author, content, followers\n",
    "    FROM tweets\n",
    "    WHERE followers > 100\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 11399.593017578125,
      "end_time": 1612356600761.666
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+\n",
      "|          language|tw_count|\n",
      "+------------------+--------+\n",
      "|              Urdu|      49|\n",
      "|          Malaysia|      27|\n",
      "|           Turkish|     373|\n",
      "|              Iraq|     275|\n",
      "|           Germany|     190|\n",
      "|       Afghanistan|      35|\n",
      "|           Kannada|       1|\n",
      "|             Malay|     216|\n",
      "|           Finnish|     520|\n",
      "|            France|      11|\n",
      "|              Thai|      33|\n",
      "|         Icelandic|     455|\n",
      "|            Pushto|     309|\n",
      "|            Somali|     238|\n",
      "|        Indonesian|     155|\n",
      "|LANGUAGE UNDEFINED|    8143|\n",
      "|              null|     157|\n",
      "|         Ukrainian|   34620|\n",
      "|Tagalog (Filipino)|     215|\n",
      "|     United States|   14809|\n",
      "+------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "se.sql(f\"\"\"\n",
    "    SELECT {}\n",
    "    FROM tweets\n",
    "    WHERE followers > 100\n",
    "    GROUP BY language\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 9376.43310546875,
      "end_time": 1612356690299.877
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|     language|tw_count|\n",
      "+-------------+--------+\n",
      "|      English| 1913019|\n",
      "|      Russian|  546315|\n",
      "|       German|   61941|\n",
      "|    Ukrainian|   34620|\n",
      "|United States|   14809|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top5_lang = se.sql(\"\"\"\n",
    "    SELECT language, count(*) as tw_count\n",
    "    FROM tweets\n",
    "    WHERE followers > 100\n",
    "    GROUP BY language\n",
    "    ORDER BY tw_count DESC\n",
    "    LIMIT 5\n",
    "\"\"\")\n",
    "top5_lang.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 9388.822021484375,
      "end_time": 1612356771768.614
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|     language|\n",
      "+-------------+\n",
      "|      English|\n",
      "|      Russian|\n",
      "|       German|\n",
      "|    Ukrainian|\n",
      "|United States|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "only_langs_df = se.sql(\"\"\"\n",
    "    SELECT language\n",
    "    FROM (\n",
    "        SELECT language, count(*) as tw_count\n",
    "        FROM tweets\n",
    "        WHERE followers > 100\n",
    "        GROUP BY language\n",
    "        ORDER BY tw_count DESC\n",
    "        LIMIT 5\n",
    "    )\n",
    "\"\"\")\n",
    "only_langs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 261.72998046875,
      "end_time": 1612356783401.478
     }
    }
   },
   "outputs": [],
   "source": [
    "only_langs_df.registerTempTable('languages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 9367.490966796875,
      "end_time": 1612356833696.505
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+\n",
      "|         author|language|\n",
      "+---------------+--------+\n",
      "|CARRIETHORNTHON| English|\n",
      "|CARRIETHORNTHON| English|\n",
      "|CARRIETHORNTHON| English|\n",
      "|CARRIETHORNTHON| English|\n",
      "|CARRIETHORNTHON| English|\n",
      "|CARRIETHORNTHON| English|\n",
      "|CARRIETHORNTHON| English|\n",
      "|CARRIETHORNTHON| English|\n",
      "|CARRIETHORNTHON| English|\n",
      "|CARRIETHORNTHON| English|\n",
      "+---------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "se.sql(\"\"\"\n",
    "    SELECT author, language\n",
    "    FROM tweets\n",
    "    WHERE language in (SELECT * FROM languages)\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 9543.322021484375,
      "end_time": 1612356868278.254
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+\n",
      "|         author|language|\n",
      "+---------------+--------+\n",
      "|CARRIETHORNTHON| English|\n",
      "|CARRIETHORNTHON| English|\n",
      "|CARRIETHORNTHON| English|\n",
      "|CARRIETHORNTHON| English|\n",
      "|CARRIETHORNTHON| English|\n",
      "|CARRIETHORNTHON| English|\n",
      "|CARRIETHORNTHON| English|\n",
      "|CARRIETHORNTHON| English|\n",
      "|CARRIETHORNTHON| English|\n",
      "|CARRIETHORNTHON| English|\n",
      "+---------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "se.sql(\"\"\"\n",
    "    SELECT author, t.language\n",
    "    FROM tweets t\n",
    "        inner join languages l on l.language = t.language\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 290.721923828125,
      "end_time": 1612356987925.346
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENGLISH', 'RUSSIAN', 'GERMAN', 'UKRAINIAN', 'UNITED STATES']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Из под датафрейма всегда можно вынуть RDD и работать напрямую уже с ним\n",
    "\n",
    "top5_lang.rdd.map(lambda x: x.language.upper()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 798.162841796875,
      "end_time": 1612357015786.159
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(language='English', tw_count=1913019),\n",
       " Row(language='Russian', tw_count=546315),\n",
       " Row(language='German', tw_count=61941),\n",
       " Row(language='Ukrainian', tw_count=34620),\n",
       " Row(language='United States', tw_count=14809)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5_lang.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
